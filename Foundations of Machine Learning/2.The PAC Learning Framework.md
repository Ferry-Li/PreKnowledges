# 2  The PAC Learning Framework

### 2.1 The PAC learning model

- Several definitions and notations

$\mathcal{X}$: set of all possible examples of instances, or the input space

$\mathcal{Y}$: labels or target values

$c:\mathcal{X} \to \mathcal{Y}$: a mapping from $\mathcal{X}$ to 

$i.i.d$: independently and identically distributed

$\mathcal{H}$: a hypothesis set

- Generalization error

$$
R(h)=\mathop{\mathbb{P}}\limits_{x \sim D}[h(x) \ne c(x)]=\mathop{\mathbb{E}}\limits_{x\sim D}[1_{h(x) \ne c(x)}]
$$

$1_w$ is the indicator function of the event $w$. It can measure the empirical error of a hypothesis, but not directly accessible since both the distribution $\mathcal{D}$ and the target concept $c$ are unknown.

- Empirical error

$$
\widehat{R}_{S}(h)=\frac{1}{m}\sum^m_{i=1}1_{h(x_i) \ne c(x_i)}
$$

The empirical error of $h \in \mathcal{H}$ is its average error over samples $S$, while the generalization error is its expected error based on the distribution $\mathcal{D}$.

For a **fixed** $h \in \mathcal{H}$, the expectation of the empirical error based on an i.i.d samples $S$ is equal to the generalization error:
$$
\mathop{\mathbb{E}}\limits_{S \sim D^m}[\widehat{R}_S(h)]=R(h)
$$

- Definition of PAC-Learning

  A concept class $C$ is PAC-learnable if there exists an algorithm $\mathcal{A} $ and a polynomial function poly(), for any $\epsilon$ and $\delta$ > 0, the following holds for any sample size $m \ge poly(1/\epsilon,1/\delta, size(C))$ 

$$
\mathop{\mathbb{P}}\limits_{S\sim \mathcal{D}^m}[R(h_S) \le \epsilon] \ge 1-\delta
$$

​		PAC -- AC: approximately correct (error at $\epsilon$) -- accuracy ($1-\epsilon$)

​		PAC -- P: high probability (at least $1-\delta$) -- confidence ($1-\delta$)

- some key points of the PAC definition
  - No particular assumption is made about the distribution $\mathcal{D}$.
  - Samples are drawn from the same distribution $\mathcal{D}$.
  - It deals with the question of the learnability of a concept class $\mathcal{C}$ and not a particular concept.

##### Example: Learning axis-aligned rectangles

![image-20220905152648211](C:\Users\21156\AppData\Roaming\Typora\typora-user-images\image-20220905152648211.png)

- false negatives: within R, but outside R'
- false positives: within R', but outside R

![image-20220905152837521](C:\Users\21156\AppData\Roaming\Typora\typora-user-images\image-20220905152837521.png)

![image-20220905160647455](C:\Users\21156\AppData\Roaming\Typora\typora-user-images\image-20220905160647455.png)
$$
s_4=\inf\{s:\mathbb{P}[[l,s] \times [b,t]] \ge \epsilon /4\} \\
r_4=[l,s_4] \times [b, t]
$$
if $R(\mathsf{R_S})>\epsilon$, then $\mathsf{R_S}$ must miss at least one of the regions $r_i$.

So, $R(\mathsf{R_S}) \Rightarrow \bigcup_{i=1}^{4} \{\mathsf{R_S} \cap r_i = \phi\}$.
$$
\begin{aligned}
\mathop{\mathbb{P}}\limits_{S\sim D^m}[R(\mathsf{R_S})] 

& \le \mathop{\mathbb{P}}\limits_{S \sim D^m}[\cup_{i=1}^4 \{\mathsf{R_S} \cap r_i=\phi\}] \\
& \le \sum_{i=1}^4 \mathop{\mathbb{P}}\limits_{S \sim D}[\mathsf{R_S} \cap r_i = \phi] \\
& \le 4(1-\epsilon/4)^m \\
& \le 4\exp(-m\epsilon/4) 
\end{aligned}
$$
To ensure $\mathop{\mathbb{P}}\limits_{S\sim \mathcal{D}^m}[R(h_S) > \epsilon] \le \delta$, we have:
$$
4exp(-m\epsilon/4) \le \delta \Leftrightarrow m \ge \frac{4}{\epsilon}\log\frac{4}{\delta}
$$
Thus, if the sample size $m$ is greater than $\frac{4}{\epsilon} \log\frac{4}{\delta}$, the concept class is PAC-learnable.

### 2.2 Guarantees for finite hypothesis sets ---- consistent case

##### Learning Bound

Let $\mathcal{A}$ be an algorithm that for any target concept $c \in  \mathcal{H}$ and i.i.d sample $S$ returns a consistent hypothesis $h_s:\widehat{R}_S(h_S)=0$. Then, for any $\epsilon,\delta>0$, the inequality $\mathbb{P}_{S\sim \mathcal{D}^m}[R(h_S) \le \epsilon] \ge 1-\delta$ holds if
$$
m \ge \frac{1}{\epsilon}(\log |\mathcal{H}|+\log\frac{1}{\delta})
$$
This result gives a generalization bound: for any $\epsilon,\delta>0$, with probability at least $1-\delta$,
$$
R(h_S) \le \frac{1}{m}(\log |\mathcal{H}| + \log \frac{1}{\delta})
$$

##### Proof.

Define $\mathcal{H}_\epsilon=\{h\in H:R(h)>\epsilon\}$.

For a single sample, we have: $\mathbb{P}[h(x)=c(x)|h\in\mathcal{H}_\epsilon] \le 1-\epsilon$.

For $S\sim \mathcal{D}^m$, we have: $\mathbb{P}[\widehat{R}_S(h)=0|h\in\mathcal{H}_\epsilon]\le(1-\epsilon)^m$.
$$
\begin{aligned}
\mathbb{P}[\exist h\in\mathcal{H}_\epsilon:\widehat{R}_S(h)=0]
&=\mathbb{P}[\widehat{R}_S(h_1)=0 \vee \dots \vee\widehat{R}_S(h_{|\mathcal{H}|})=0] \\
&\le \sum_{h\in\mathcal{H_\epsilon}}\mathbb{P}[\widehat{R}_S(h)=0] \\
&\le \sum_{h\in\mathcal{H}_\epsilon}(1-\epsilon)^m
\le |\mathcal H|(1-\epsilon)^m 
\le |\mathcal H|e^{-m\epsilon}
\end{aligned} \\

\begin{aligned}
|\mathcal{H}|e^{-m\epsilon} \le \delta &\Rightarrow \frac{|\mathcal H|}{\delta} \le e^{m\epsilon} \\
& \Rightarrow \frac{1}{\epsilon}\log\frac{|\mathcal H|}{\delta} \le m \\
& \Rightarrow  m \ge \frac{1}{\epsilon}(\log |\mathcal{H}|+\log\frac{1}{\delta})

\end{aligned}
$$
The generalization error of consistent hypothesis is upper bounded by a term that decreases as a function of the sample size $m$. **Learning algorithms benefit from larger labeled training samples.**

### 2.3 Guarantees for finite hypothesis sets ---- inconsistent sets

For consistent hypothesis sets, we can find $h_s \in \mathcal{H}, \widehat{R}(h_S)=0$, so the guarantees can be described as : $\mathbb{P}[R(h_S)>\epsilon]\le\delta$.

For inconsistent hypothesis sets, we sometimes can't find such $h_S \in  \mathcal{H}$. Therefore, the guarantees have to be described as : $\mathbb{P}[|\widehat{R}_S(h)-R(h)|\ge \epsilon]\le\delta$.

##### Corollary

Fix $\epsilon>0$, for any hypothesis h: $X \to \{0, 1\}$, the following inequalities hold:
$$
\mathop{\mathbb{P}}\limits_{S \in \mathcal{D}^m}[|\widehat{R}_S(h)-R(h)|\ge \epsilon]\le2\exp(-2m\epsilon^2)
$$

##### Theorem -- Learning Bound for finite $\mathcal{H}$, inconsistent case

Let $\mathcal{H}$ be a finite hypothesis set. Then, for any $\delta>0$, with probability at least $1-\delta$, the following inequality holds:
$$
\forall h\in \mathcal{H}, R(h) \le \widehat{R}_S(h)+\sqrt{\frac{\log |H|+\log \frac{2}{\delta}}{2m}}
$$
Proof: 
$$
\begin{aligned}
\mathbb{P}[\exist h \in \mathcal{H}&| \widehat{R}_S(h)-R(h)| > \epsilon] \\
& =\mathbb{P}[(|\widehat{R}_s(h_1)-R(h_1)|>\epsilon)\vee \dots \vee (|\widehat{R}_s(h_\mathcal{H})-R(h_\mathcal{H})|>\epsilon)] \\
& \le\sum_{h\in\mathcal{H}}\mathbb{P}[|\widehat{R}_S(h)-R(h)|>\epsilon] \\
& \le 2 |\mathcal{H}|\exp(-2m\epsilon^2)=\delta
\end{aligned} \\
$$
A larger hypothesis set is penalized by the second term, but could help reduce $\widehat{R}_S(h)$. --> Occam's Razor Principle.

### 2.4 Generalities

##### Agnostic PAC-Learning

$$
\mathop{\mathbb{P}}\limits_{S\sim \mathcal{D}^m}[R(h_S)-\mathop{\min}\limits_{h\in \mathcal{H}}R(h) \le \epsilon] \ge 1-\delta 
$$

The output is a probabilistic function of the input. Labels are not unique.

##### Bayes error

$$
R^*=\mathop{\inf}\limits_h R(h)
$$

A hypothesis h with $R(h)=R^*$ is called a Bayes hypothesis or Bayes classifier.

The Bayes classifier can be defined in terms of the conditional probabilities as:
$$
\forall x \in \mathcal{X}, h_{Bayes}(x)=\mathop{argmax}\limits_{y\in\{0, 1\}}\mathbb{P}[y|x]
$$
The average error made by $h_bayes$ on $x\in\mathcal{X}$ is $\min \{\mathbb{P}[0|x],\mathbb{P}[1|x]\}$.

##### Noise

$$
noise(x)=\min \{\mathbb{P}[0|x],\mathbb{P}[1|x]\}
$$

The average noise is precisely the Bayes error: $noise=\mathbb{E}[noise(x)]=R^*$. It is a characteristic of the learning task indicating its level of difficulty.

